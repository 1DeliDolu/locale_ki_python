Ä°ÅŸte metnin TÃ¼rkÃ§eye Ã§evrilmiÅŸ hali; konu bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ne gÃ¶re paragraflara ayrÄ±lmÄ±ÅŸ ve her baÅŸlÄ±ÄŸa emoji eklenmiÅŸtir:

---

### ğŸ–¼ï¸ Yapay ZekÃ¢ ile FotoÄŸraflarÄ±nÄ±za AnlamlÄ± Ä°simler Verin

**cognitiveclass.ai logosu**

---

### ğŸŒŸ GiriÅŸ

GÃ¶rseller, henÃ¼z deÄŸerlendirilmemiÅŸ zengin bilgiler barÄ±ndÄ±rÄ±r, ancak arama motorlarÄ± ve veri sistemleri bu iÃ§erikleri genellikle gÃ¶z ardÄ± eder. GÃ¶rsel veriyi makine tarafÄ±ndan okunabilir dile dÃ¶nÃ¼ÅŸtÃ¼rmek kolay deÄŸildir, ancak burada **gÃ¶rsel aÃ§Ä±klama yapay zekÃ¢sÄ± (image captioning AI)** devreye girer.

Ä°ÅŸte bu teknolojinin nasÄ±l fark yaratabileceÄŸi:

* **EriÅŸilebilirliÄŸi artÄ±rÄ±r:** GÃ¶rme engelli bireylerin gÃ¶rsel iÃ§erikleri anlamasÄ±na yardÄ±mcÄ± olur.
* **SEO'yu iyileÅŸtirir:** Arama motorlarÄ±nÄ±n gÃ¶rsel iÃ§erikleri tanÄ±masÄ±nÄ± saÄŸlar.
* **Ä°Ã§erik keÅŸfini kolaylaÅŸtÄ±rÄ±r:** BÃ¼yÃ¼k gÃ¶rsel veritabanlarÄ±nÄ±n analizini ve kategorilendirilmesini hÄ±zlandÄ±rÄ±r.
* **Sosyal medya ve reklamcÄ±lÄ±ÄŸÄ± destekler:** GÃ¶rsel iÃ§erikler iÃ§in etkileyici aÃ§Ä±klamalarÄ± otomatik Ã¼retir.
* **GÃ¼venliÄŸi artÄ±rÄ±r:** Video kayÄ±tlarÄ±nda gerÃ§ek zamanlÄ± etkinlik aÃ§Ä±klamalarÄ± saÄŸlar.
* **EÄŸitim ve araÅŸtÄ±rmada kullanÄ±lÄ±r:** GÃ¶rsel materyallerin anlaÅŸÄ±lmasÄ±nÄ± ve yorumlanmasÄ±nÄ± kolaylaÅŸtÄ±rÄ±r.
* **Ã‡ok dilli destek sunar:** FarklÄ± dillerde aÃ§Ä±klamalar Ã¼reterek kÃ¼resel eriÅŸim saÄŸlar.
* **Veri organizasyonu saÄŸlar:** BÃ¼yÃ¼k gÃ¶rsel veri kÃ¼melerinin yÃ¶netimi ve sÄ±nÄ±flandÄ±rÄ±lmasÄ±nÄ± destekler.
* **Zamandan tasarruf saÄŸlar:** Otomatik aÃ§Ä±klamalar, manuel etiketlemeden Ã§ok daha verimlidir.
* **KullanÄ±cÄ± etkileÅŸimini artÄ±rÄ±r:** DetaylÄ± aÃ§Ä±klamalar, gÃ¶rselleri daha ilgi Ã§ekici ve bilgilendirici kÄ±lar.

---

### ğŸ¯ Ã–ÄŸrenme Hedefleri

Bu projeyi tamamladÄ±ÄŸÄ±nÄ±zda ÅŸunlarÄ± yapabileceksiniz:

* **Hugging Faceâ€™in Transformers kÃ¼tÃ¼phanesinden BLIP modelini** kullanarak bir gÃ¶rsel aÃ§Ä±klama aracÄ± geliÅŸtirmek
* **Gradio** ile kullanÄ±cÄ± dostu bir arayÃ¼z oluÅŸturmak
* **GerÃ§ek dÃ¼nya iÅŸ senaryolarÄ±na** uygun ÅŸekilde aracÄ± uyarlamak ve uygulamalÄ± kullanÄ±m Ã¶rneklerini gÃ¶stermek

![1748460276084](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460276084.png)

### ğŸ› ï¸ OrtamÄ± HazÄ±rlama ve Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleme

Bu projede bir yapay zekÃ¢ uygulamasÄ± geliÅŸtirmek iÃ§in Hugging Face tarafÄ±ndan saÄŸlanan **Gradio arayÃ¼zÃ¼nÃ¼** kullanacaksÄ±nÄ±z.

Haydi, proje iÃ§in ortamÄ± ve baÄŸÄ±mlÄ±lÄ±klarÄ± birlikte hazÄ±rlayalÄ±m. AÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edin:

---

### ğŸ’» Yeni Bir Terminal AÃ§Ä±n

1. Yeni bir terminal penceresi aÃ§Ä±n.
2. Projenizin bulunduÄŸu dizine gidin (Ã¶rneÄŸin `home/project` klasÃ¶rÃ¼).

![1748460314683](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460314683.png)

### âš™ï¸ Python Sanal Ortam OluÅŸturma ve KÃ¼tÃ¼phaneleri YÃ¼kleme

Projeyi izole bir ortamda geliÅŸtirmek iÃ§in bir Python **sanal ortamÄ±** oluÅŸturacaÄŸÄ±z ve gerekli kÃ¼tÃ¼phaneleri bu ortama kuracaÄŸÄ±z.

---

### ğŸ§ª AdÄ±m 1: Sanal OrtamÄ± OluÅŸtur ve EtkinleÅŸtir

Terminalde aÅŸaÄŸÄ±daki komutlarÄ± sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
pip3 install virtualenv 
virtualenv my_env  # my_env adÄ±nda bir sanal ortam oluÅŸturulur
source my_env/bin/activate  # OrtamÄ± etkinleÅŸtirir
```

---

### ğŸ“¦ AdÄ±m 2: Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin

EtkinleÅŸtirilmiÅŸ ortamda ÅŸu komutu Ã§alÄ±ÅŸtÄ±rarak gerekli tÃ¼m kÃ¼tÃ¼phaneleri kurun:

```bash
pip install langchain==0.1.11 gradio==5.23.2 transformers==4.38.2 bs4==0.0.2 requests==2.31.0 torch==2.2.1
```

---

### â˜• Kurulum SÃ¼rerken Kahve MolasÄ±

Kurulum yaklaÅŸÄ±k 5 dakika sÃ¼rebilir. Bu sÄ±rada biraz rahatlayÄ±n:

```
      )  (
     (   ) )
      ) ( (
    _______)_
 .-'---------|
( C|/\/\/\/\/|
 '-./\/\/\/\/|
   '_________'
    '-------'
```

---

### âœ… HazÄ±r!

ArtÄ±k Python dosyalarÄ±nÄ± oluÅŸturmak ve geliÅŸtirmeye baÅŸlamak iÃ§in ortamÄ±nÄ±z hazÄ±r.

Devam etmek ister misiniz? Bir `caption_app.py` dosyasÄ± oluÅŸturup kodlamaya geÃ§ebiliriz.

![1748460359661](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460359661.png)

---

### ğŸ§  KullanacaÄŸÄ±nÄ±z BileÅŸenler: AutoProcessor ve BlipForConditionalGeneration

Bu projede Hugging Face Transformers kÃ¼tÃ¼phanesinden ÅŸu bileÅŸenleri kullanacaksÄ±nÄ±z:

---

### ğŸ› ï¸ AutoProcessor Nedir?

 **`AutoProcessor`** , BLIP modeli iÃ§in veri Ã¶n iÅŸleme yapan bir yardÄ±mcÄ± sÄ±nÄ±ftÄ±r.

* **GÃ¶rsel iÅŸlemeyi (image processor)** ve **metin Ã§Ã¶zÃ¼mleyiciyi (OPT/T5 tokenizer)** bir araya getirir.
* Hem gÃ¶rsel hem metin verisini alarak, bu verileri model iÃ§in hazÄ±r hale getirir.

ğŸ“Œ *Not:*

Tokenizer, doÄŸal dil iÅŸleme alanÄ±nda metni daha kÃ¼Ã§Ã¼k parÃ§alara (token) ayÄ±rarak modelin metni analiz edebilmesini saÄŸlar. Bu parÃ§alar genellikle kelimeler veya kelime Ã¶bekleridir.

---

### âœï¸ BlipForConditionalGeneration Nedir?

 **`BlipForConditionalGeneration`** , bir gÃ¶rsel (ve isteÄŸe baÄŸlÄ± olarak bir metin girdisi) verildiÄŸinde aÃ§Ä±klayÄ±cÄ± metin Ã¼retimi (captioning) yapan bir model sÄ±nÄ±fÄ±dÄ±r.

* GÃ¶rsel aÃ§Ä±klama (image captioning)
* GÃ¶rsel soru-cevap (visual question answering)

  gibi gÃ¶revlerde kullanÄ±lÄ±r.

---

### ğŸ“¥ AdÄ±m 1: KÃ¼tÃ¼phaneleri ve Modeli YÃ¼kleme

AÅŸaÄŸÄ±daki Python kodunu kullanarak model bileÅŸenlerini yÃ¼kleyin:

```python
import requests
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration

# Ã–nceden eÄŸitilmiÅŸ iÅŸlemci ve modeli yÃ¼kleyin
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
```

---

### ğŸ–¼ï¸ AdÄ±m 2: GÃ¶rseli HazÄ±rlamak

AÃ§Ä±klanacak gÃ¶rseli hazÄ±rlamak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

1. Kod editÃ¶rÃ¼nÃ¼zÃ¼n sol tarafÄ±ndaki **Explorer (Dosya Gezgininde)** boÅŸ bir alana saÄŸ tÄ±klayÄ±n.
2. **Upload Files...** seÃ§eneÄŸine tÄ±klayÄ±n.
3. BilgisayarÄ±nÄ±zdan bir gÃ¶rsel seÃ§ip yÃ¼kleyin.
4. Kodda `img_path` deÄŸerini yÃ¼klediÄŸiniz gÃ¶rselin adÄ±yla deÄŸiÅŸtirin.

---

![1748460415484](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460415484.png)

---

### ğŸ–¼ï¸ Dosya YÃ¼kleme: GÃ¶rseli HazÄ±rlama

Sonraki aÅŸamada, eÄŸitilmiÅŸ modeliniz tarafÄ±ndan aÃ§Ä±klanacak bir gÃ¶rsel alacaksÄ±nÄ±z.

Bu gÃ¶rsel ister yerel dosya olarak bilgisayarÄ±nÄ±zdan, ister bir URL Ã¼zerinden alÄ±nabilir.

GÃ¶rsel, Python Imaging Library ( **PIL** ) ile aÃ§Ä±lÄ±r ve modele uygun hale getirmek iÃ§in **RGB formatÄ±na** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

```python
# GÃ¶rselinizi yÃ¼kleyin â€“ GÃ–RSEL ADINI UNUTMAYIN!
img_path = "GORSEL_ADINIZ.jpeg"
# RGB formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
image = Image.open(img_path).convert('RGB')
```

---

### ğŸ§ª GÃ¶rseli Ä°ÅŸleyip Model Girdisine DÃ¶nÃ¼ÅŸtÃ¼rme

Ä°ÅŸlenen gÃ¶rsel, `processor` aracÄ±lÄ±ÄŸÄ±yla modele uygun girdiye Ã§evrilir.

`return_tensors="pt"` argÃ¼manÄ±, Ã§Ä±ktÄ±nÄ±n PyTorch tensÃ¶rÃ¼ olarak dÃ¶nmesini saÄŸlar.

```python
# GÃ¶rsel aÃ§Ä±klama iÃ§in soruya gerek yok
text = "the image of"
inputs = processor(images=image, text=text, return_tensors="pt")
```

---

### ğŸ¤– Model ile AÃ§Ä±klama Ãœretimi

Modelin `generate` metodu kullanÄ±larak aÃ§Ä±klama oluÅŸturulur.

`max_new_tokens=50` parametresi, en fazla 50 tokenâ€™lÄ±k aÃ§Ä±klama Ã¼retmesini belirtir.

ğŸ“Œ Not: Python'da `**` iÅŸareti, bir sÃ¶zlÃ¼ÄŸÃ¼ aÃ§arak anahtar-deÄŸer Ã§iftlerini fonksiyona argÃ¼man olarak iletmek iÃ§in kullanÄ±lÄ±r.

```python
# GÃ¶rsel iÃ§in aÃ§Ä±klama Ã¼ret
outputs = model.generate(**inputs, max_length=50)
```

---

### ğŸ“ Ãœretilen AÃ§Ä±klamayÄ± Okunabilir Metne DÃ¶nÃ¼ÅŸtÃ¼rme

Modelin Ã¼rettiÄŸi Ã§Ä±ktÄ±, token dizisidir. Bu diziyi insan tarafÄ±ndan okunabilir metne Ã§evirmek iÃ§in `decode` metodu kullanÄ±lÄ±r.

`skip_special_tokens=True` ile Ã¶zel karakterler Ã§Ä±ktÄ±dan Ã§Ä±karÄ±lÄ±r.

```python
# Ãœretilen token'larÄ± metne Ã§evir
caption = processor.decode(outputs[0], skip_special_tokens=True)
# AÃ§Ä±klamayÄ± yazdÄ±r
print(caption)
```

---

### ğŸ’¾ Python DosyasÄ±nÄ± Kaydet ve Ã‡alÄ±ÅŸtÄ±r

KodlarÄ±nÄ±zÄ± bir dosyaya (Ã¶rneÄŸin `image_cap.py`) kaydedin ve ÅŸu komutla Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python3 image_cap.py
```

---

### âœ… SonuÃ§: GÃ¶rselin AÃ§Ä±klamasÄ± HazÄ±r!

Modelinizin Ã¼rettiÄŸi aÃ§Ä±klama, gÃ¶rselin iÃ§eriÄŸini metin olarak ifade eder.

Bu aÃ§Ä±klama, **BLIP modeli** tarafÄ±ndan gÃ¶rselin analiz edilip yorumlanmasÄ±yla elde edilir.

HazÄ±rsan, bu projeyi Gradio arayÃ¼zÃ¼yle birleÅŸtirip etkileÅŸimli hale getirebiliriz. Devam edelim mi?

![1748460444651](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460444651.png)

### ğŸ’» Gradio ile GÃ¶rsel AÃ§Ä±klama UygulamasÄ±

ArtÄ±k **gÃ¶rsel aÃ§Ä±klama mekanizmasÄ±nÄ±** anladÄ±ÄŸÄ±nÄ±za gÃ¶re, bunu **kullanÄ±cÄ± dostu bir arayÃ¼zle birleÅŸtirerek gerÃ§ek bir uygulama** haline getirebiliriz.

Bu amaÃ§la, Hugging Face tarafÄ±ndan sunulan **Gradio** aracÄ±nÄ± kullanacaÄŸÄ±z.

---

### ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§: Gradio ile Basit Bir Demo

Gradioâ€™ya alÄ±ÅŸmak iÃ§in Ã¶nce kÃ¼Ã§Ã¼k bir uygulama oluÅŸturalÄ±m.

ğŸ“ HÃ¢lÃ¢ proje klasÃ¶rÃ¼ndeyken ÅŸu adÄ±mlarÄ± izleyin:

1. Yeni bir Python dosyasÄ± oluÅŸturun.
2. Dosyaya ÅŸu ismi verin: `hello.py`

---

![1748460498479](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460498479.png)

---

### ğŸ‘¨â€ğŸ’» `hello.py` DosyasÄ±nÄ± OluÅŸtur ve Kodu YapÄ±ÅŸtÄ±r

Yeni oluÅŸturduÄŸun `hello.py` dosyasÄ±nÄ± aÃ§ ve aÅŸaÄŸÄ±daki Python kodunu iÃ§erisine kopyalayÄ±p kaydet:

```python
import gradio as gr

def greet(name):
    return "Hello " + name + "!"

demo = gr.Interface(fn=greet, inputs="text", outputs="text")
demo.launch(server_name="0.0.0.0", server_port=7860)
```

---

### ğŸ§ª Ne Yapar Bu Kod?

YukarÄ±daki kod, `demo` adÄ±nda bir **`gr.Interface`** oluÅŸturur.

Bu arayÃ¼z, **`greet()` fonksiyonunu** basit bir **metin giriÅŸinden metin Ã§Ä±ktÄ±sÄ±na** kullanÄ±cÄ± arayÃ¼zÃ¼yle sarar.

`gr.Interface` sÄ±nÄ±fÄ± ÅŸu 3 temel parametreyle baÅŸlatÄ±lÄ±r:

* `fn`: ArayÃ¼zle sarÄ±lacak fonksiyon
* `inputs`: GiriÅŸ bileÅŸeni (Ã¶rneÄŸin: `"text"`, `"image"`, `"audio"`)
* `outputs`: Ã‡Ä±kÄ±ÅŸ bileÅŸeni (Ã¶rneÄŸin: `"text"`, `"image"`, `"label"`)

Son satÄ±rdaki `demo.launch()` ifadesi, uygulamayÄ± barÄ±ndÄ±racak yerel sunucuyu baÅŸlatÄ±r.

---

### ğŸš€ Demo UygulamayÄ± BaÅŸlatmak

Terminale geri dÃ¶n ve `my_env` sanal ortamÄ±nÄ±n etkin olduÄŸunu kontrol et. SatÄ±rÄ±n baÅŸÄ±nda `(my_env)` ibaresi gÃ¶rÃ¼nmelidir.

UygulamayÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in ÅŸu komutu yaz:

```bash
python3 hello.py
```

---

### ğŸŒ Web ArayÃ¼zÃ¼nÃ¼ GÃ¶rÃ¼ntÃ¼le

Kod, localhost (127.0.0.1) Ã¼zerinden servis edildiÄŸinden, tarayÄ±cÄ±na ÅŸu adresi yazabilirsin:

ğŸ‘‰ [http://127.0.0.1:7860](http://127.0.0.1:7860)

---

### ğŸ§¾ Ne GÃ¶receksiniz?

Girdi alanÄ±na adÄ±nÄ±zÄ± yazÄ±n (Ã¶rneÄŸin: `bob`), **Submit** tuÅŸuna basÄ±n.

SaÄŸda ÅŸu Ã§Ä±ktÄ±yÄ± gÃ¶receksiniz:

```
Hello bob!
```

---

![1748460530041](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460530041.png)

Uygulama ile oynamayÄ± bitirdiÄŸinizde Ã§Ä±kmak iÃ§in:

**Terminalde `Ctrl + C` tuÅŸlarÄ±na basÄ±n** ve ardÄ±ndan tarayÄ±cÄ±daki uygulama sekmesini kapatÄ±n.

---

### ğŸ‰ Ä°lk Gradio Deneyiminiz

Gradio arayÃ¼zÃ¼nÃ¼ ilk kez denediniz â€” **kolay deÄŸil mi?**

Basit birkaÃ§ satÄ±r kodla etkileÅŸimli bir web uygulamasÄ± oluÅŸturabildiniz.

---

### ğŸ“š Daha Fazla Ã–ÄŸrenmek Ä°ster Misiniz?

Gradio hakkÄ±nda daha fazla Ã¶zelleÅŸtirme Ã¶ÄŸrenmek isterseniz, sizi ÅŸu rehberli projeye davet ediyoruz:

**â€œBring your Machine Learning Model to Life with Gradioâ€**

Bu projeyi **[cognitiveclass.ai](https://cognitiveclass.ai)** platformunda, **Courses & Projects** bÃ¶lÃ¼mÃ¼nde bulabilirsiniz!

---

### ğŸ§ª Uygulama: Gradio ile GÃ¶rsel AÃ§Ä±klama (Image Captioning) UygulamasÄ± GeliÅŸtirme

Bu egzersizde, **BLIP-2 modeli** ve **Gradio kÃ¼tÃ¼phanesini** kullanarak gÃ¶rseller iÃ§in aÃ§Ä±klama Ã¼reten bir web uygulamasÄ± geliÅŸtireceksiniz. AÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

---

### ğŸ”§ AdÄ±m 1: OrtamÄ± HazÄ±rlayÄ±n

ğŸ“Œ Gerekli kÃ¼tÃ¼phanelerin kurulu olduÄŸundan emin olun. Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
pip install gradio transformers Pillow
```

ğŸ“ ArdÄ±ndan yeni bir Python dosyasÄ± oluÅŸturun ve adÄ±nÄ± `image_captioning_app.py` koyun.

Ä°Ã§ine aÅŸaÄŸÄ±daki kÃ¼tÃ¼phaneleri ekleyin:

```python
import gradio as gr
import numpy as np
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration
```

---

### ğŸ“¦ AdÄ±m 2: Ã–nceden EÄŸitilmiÅŸ Modeli YÃ¼kleyin

AÅŸaÄŸÄ±daki kodla `processor` ve `model` bileÅŸenlerini yÃ¼kleyin:

```python
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
```

---

### ğŸ§  AdÄ±m 3: GÃ¶rsel AÃ§Ä±klama Fonksiyonunu TanÄ±mlayÄ±n

AÃ§Ä±klama Ã¼retimi iÃ§in aÅŸaÄŸÄ±daki fonksiyonu yazÄ±n:

```python
def caption_image(input_image: np.ndarray):
    # NumPy dizisini PIL Image'e Ã§evir ve RGB formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    raw_image = Image.fromarray(input_image).convert('RGB')
  
    # GÃ¶rseli iÅŸle
    inputs = processor(images=raw_image, return_tensors="pt")

    # AÃ§Ä±klama Ã¼ret
    outputs = model.generate(**inputs, max_length=50)

    # Token'larÄ± okunabilir metne Ã§evir
    caption = processor.decode(outputs[0], skip_special_tokens=True)
  
    return caption
```

---

### ğŸŒ AdÄ±m 4: Gradio ArayÃ¼zÃ¼nÃ¼ OluÅŸturun

Åimdi uygulama arayÃ¼zÃ¼nÃ¼ tanÄ±mlayÄ±n:

```python
iface = gr.Interface(
    fn=caption_image, 
    inputs=gr.Image(), 
    outputs="text",
    title="Image Captioning",
    description="Bu uygulama, eÄŸitilmiÅŸ bir model kullanarak gÃ¶rseller iÃ§in aÃ§Ä±klama Ã¼retir."
)
```

---

### ğŸš€ AdÄ±m 5: UygulamayÄ± BaÅŸlatÄ±n

Gradio uygulamasÄ±nÄ± baÅŸlatmak iÃ§in ÅŸu satÄ±rÄ± ekleyin:

```python
iface.launch()
```

---

### ğŸ’» AdÄ±m 6: UygulamayÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n

TÃ¼m kodu `image_captioning_app.py` dosyasÄ±na kaydedin.

Terminali aÃ§Ä±n, dosyanÄ±n bulunduÄŸu dizine gidin ve ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python3 image_captioning_app.py
```

TarayÄ±cÄ±da aÃ§Ä±lan uygulamada gÃ¶rsel yÃ¼kleyerek aÃ§Ä±klama Ã¼retebilirsiniz.

ğŸ“Œ Ã‡Ä±kmak iÃ§in terminalde `Ctrl + C` tuÅŸlarÄ±na basÄ±n.

---

![1748460651274](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460651274.png)


### ğŸŒ Web UygulamasÄ±yla EtkileÅŸime GeÃ§me (Yerel Olarak Ã‡alÄ±ÅŸtÄ±rÄ±yorsanÄ±z)

UygulamanÄ±z baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yorsa, terminalde aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edebilirsiniz:

1. **Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda** , terminalde bir URL gÃ¶rÃ¼ntÃ¼lenecektir (Ã¶rneÄŸin: `http://127.0.0.1:7860`).
2. Bu URLâ€™yi bir web tarayÄ±cÄ±sÄ±nda aÃ§Ä±n.
3. Ekranda **gÃ¶rsel yÃ¼kleme kutusu** bulunan bir arayÃ¼z gÃ¶receksiniz.

---

### ğŸ‰ Tebrikler!

Gradio ve BLIP modelini kullanarak bir **gÃ¶rsel aÃ§Ä±klama (image captioning)** web uygulamasÄ± oluÅŸturdunuz.

ArtÄ±k:

* ArayÃ¼zÃ¼ kiÅŸiselleÅŸtirebilir
* Kodu geliÅŸtirebilir
* FarklÄ± modelleri veya ayarlarÄ± deneyerek uygulamanÄ±n iÅŸlevselliÄŸini artÄ±rabilirsiniz

---

![1748460699245](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460699245.png)


---

### ğŸ¤– Egzersiz: Otomatik GÃ¶rsel AÃ§Ä±klama UygulamasÄ± â€“ Web SayfasÄ±ndan GÃ¶rsel Ã‡ekme ve AÃ§Ä±klama Ãœretme

Bu egzersizde, **BeautifulSoup** ile bir web sayfasÄ±ndaki tÃ¼m gÃ¶rselleri toplayacak, ardÄ±ndan **BLIP modeli** ile bu gÃ¶rsellerin aÃ§Ä±klamalarÄ±nÄ± otomatik olarak oluÅŸturacaksÄ±nÄ±z. SonuÃ§larÄ± bir `.txt` dosyasÄ±na yazdÄ±racaksÄ±nÄ±z.

---

### ğŸ§¾ AdÄ±m 1: Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleme ve DosyayÄ± OluÅŸturma

ğŸ“ Yeni bir Python dosyasÄ± oluÅŸturun:

**`automate_url_captioner.py`**

Kodun baÅŸÄ±nda aÅŸaÄŸÄ±daki kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±n ve modeli yÃ¼kleyin:

```python
import requests
from PIL import Image
from io import BytesIO
from bs4 import BeautifulSoup
from transformers import AutoProcessor, BlipForConditionalGeneration

# Ã–nceden eÄŸitilmiÅŸ iÅŸlemci ve model
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
```

---

### ğŸŒ AdÄ±m 2: Web SayfasÄ±nÄ± Ä°ndir ve HTML'i AyrÄ±ÅŸtÄ±r

```python
# GÃ¶rsellerin alÄ±nacaÄŸÄ± sayfa
url = "https://en.wikipedia.org/wiki/IBM"

# SayfayÄ± indir
response = requests.get(url)

# BeautifulSoup ile HTML'yi ayrÄ±ÅŸtÄ±r
soup = BeautifulSoup(response.text, 'html.parser')
```

---

### ğŸ–¼ï¸ AdÄ±m 3: GÃ¶rselleri Bul ve Ä°ÅŸle

```python
# TÃ¼m <img> etiketlerini bul
img_elements = soup.find_all('img')

# AÃ§Ä±klamalarÄ± yazmak iÃ§in bir dosya aÃ§
with open("captions.txt", "w") as caption_file:
    for img_element in img_elements:
        img_url = img_element.get('src')

        # SVG veya 1x1 gÃ¶rselleri atla
        if 'svg' in img_url or '1x1' in img_url:
            continue

        # Bozuk URL'leri dÃ¼zelt
        if img_url.startswith('//'):
            img_url = 'https:' + img_url
        elif not img_url.startswith('http://') and not img_url.startswith('https://'):
            continue

        try:
            # GÃ¶rseli indir
            response = requests.get(img_url)

            # GÃ¶rseli PIL formatÄ±na Ã§evir
            raw_image = Image.open(BytesIO(response.content))
            if raw_image.size[0] * raw_image.size[1] < 400:
                continue  # Ã‡ok kÃ¼Ã§Ã¼k gÃ¶rselleri atla

            raw_image = raw_image.convert('RGB')

            # GÃ¶rseli iÅŸle ve aÃ§Ä±klama Ã¼ret
            inputs = processor(raw_image, return_tensors="pt")
            out = model.generate(**inputs, max_new_tokens=50)
            caption = processor.decode(out[0], skip_special_tokens=True)

            # AÃ§Ä±klamayÄ± dosyaya yaz
            caption_file.write(f"{img_url}: {caption}\n")
        except Exception as e:
            print(f"GÃ¶rsel iÅŸlenirken hata oluÅŸtu {img_url}: {e}")
            continue
```

---

### âœ… Ã‡Ä±ktÄ±: `captions.txt`

* Kod Ã§alÄ±ÅŸtÄ±ktan sonra, bulunduÄŸun dizinde **`captions.txt`** adÄ±nda yeni bir dosya oluÅŸacaktÄ±r.
* Bu dosya, her satÄ±rda gÃ¶rsel URLâ€™si ve BLIP modeli tarafÄ±ndan oluÅŸturulan aÃ§Ä±klamayÄ± iÃ§erir.

---

![1748460788940](image/modula1_10_GiveMeaningfulNamestoYourPhotoswithIMGCaptioningAI/1748460788940.png)

---

### ğŸ–¼ï¸ Bonus: Yerel GÃ¶rseller Ä°Ã§in GÃ¶rsel AÃ§Ä±klama (BLIP-2 ile)

BLIP-2 modeli daha gÃ¼Ã§lÃ¼ bir Ã¶nceden eÄŸitilmiÅŸ modeldir ve gÃ¶rsel aÃ§Ä±klama gÃ¶revlerinde yÃ¼ksek baÅŸarÄ± saÄŸlar.

AÅŸaÄŸÄ±da, bir klasÃ¶rdeki tÃ¼m yerel gÃ¶rselleri dolaÅŸarak aÃ§Ä±klama Ã¼reten bir uygulama oluÅŸturmayÄ± Ã¶ÄŸreneceksiniz.

> âš ï¸ **Not:** BLIP-2 modeli yaklaÅŸÄ±k 10 GB boyutundadÄ±r. Bu nedenle CloudIDE gibi sÄ±nÄ±rlÄ± kaynaklÄ± ortamlarda Ã§alÄ±ÅŸmaz. Yerel Ã§alÄ±ÅŸtÄ±rmanÄ±z Ã¶nerilir.

---

### ğŸ§¾ Gerekenler

* `transformers`, `PIL`, `glob`, `os` kÃ¼tÃ¼phaneleri
* GÃ¶rsellerin bulunduÄŸu klasÃ¶r
* `Salesforce/blip2-opt-2.7b` modeli

---

### ğŸ“ Dosya YapÄ±sÄ± ve Kod

Yeni bir dosya oluÅŸturun:

**`local_blip2_captioner.py`**

```python
import os
import glob
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration

# Ã–nceden eÄŸitilmiÅŸ BLIP-2 iÅŸlemcisi ve modeli yÃ¼kleniyor
processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b")

# GÃ¶rsellerin bulunduÄŸu klasÃ¶rÃ¼ belirtin
image_dir = "/path/to/your/images"  # BurayÄ± kendi dizin yolunuzla deÄŸiÅŸtirin
image_exts = ["jpg", "jpeg", "png"]  # Desteklenen uzantÄ±lar

# AÃ§Ä±klamalarÄ± yazmak iÃ§in dosya aÃ§Ä±lÄ±yor
with open("captions.txt", "w") as caption_file:
    # Her dosya uzantÄ±sÄ± iÃ§in gÃ¶rselleri tara
    for image_ext in image_exts:
        for img_path in glob.glob(os.path.join(image_dir, f"*.{image_ext}")):
            try:
                # GÃ¶rseli yÃ¼kle ve RGB'ye Ã§evir
                raw_image = Image.open(img_path).convert('RGB')

                # BLIP-2 iÅŸlemcisi ile giriÅŸ hazÄ±rla
                inputs = processor(raw_image, return_tensors="pt")

                # Model ile aÃ§Ä±klama Ã¼ret
                out = model.generate(**inputs, max_new_tokens=50)

                # Ãœretilen token'larÄ± metne Ã§evir
                caption = processor.decode(out[0], skip_special_tokens=True)

                # AÃ§Ä±klamayÄ± dosyaya yaz
                caption_file.write(f"{os.path.basename(img_path)}: {caption}\n")
            except Exception as e:
                print(f"Hata oluÅŸtu: {img_path} â€” {e}")
                continue
```

---

### âœ… SonuÃ§

Kod Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda:

* BelirttiÄŸiniz klasÃ¶rdeki tÃ¼m `.jpg`, `.jpeg`, `.png` dosyalarÄ± iÅŸlenir
* Her gÃ¶rsel iÃ§in aÃ§Ä±klama Ã¼retilir
* AÃ§Ä±klamalar `captions.txt` dosyasÄ±na yazÄ±lÄ±r:

  Ã–rn:

  ```
  sunset.jpg: A beautiful sunset over the ocean.
  ```

---


### ğŸ SonuÃ§

ğŸ‰ **Tebrikler!**

Bu rehberli projeyi baÅŸarÄ±yla tamamladÄ±nÄ±z. ArtÄ±k **Gradio** ve **IBM Code Engine** kullanarak **gÃ¶rsel aÃ§Ä±klama yapay zekÃ¢sÄ± (image captioning AI)** oluÅŸturma konusunda uzmanlaÅŸtÄ±nÄ±z.

---

### ğŸš€ Sonraki AdÄ±mlar

#### â˜ï¸ UygulamanÄ±zÄ± Ä°nternete TaÅŸÄ±yÄ±n: IBM Code Engine ile YayÄ±nlama

Bu uygulamayÄ± internet Ã¼zerinde yayÄ±nlamak isterseniz, **IBM Code Engine** kullanarak daÄŸÄ±tÄ±m yapabilirsiniz.

Bir sonraki isteÄŸe baÄŸlÄ± bÃ¶lÃ¼mde, bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± adÄ±m adÄ±m gÃ¶steren bir rehber sunulmaktadÄ±r.

---

### âš™ï¸ Kubernetes ile Uygulama YayÄ±nlama

Projenin sonunda, IBM Developer Skills Network tarafÄ±ndan saÄŸlanan **paylaÅŸÄ±mlÄ± bir Kubernetes kÃ¼mesine** uygulamanÄ±zÄ± baÅŸarÄ±yla daÄŸÄ±ttÄ±nÄ±z.

ğŸ“Œ EÄŸer:

* UygulamanÄ±zÄ±n **kalÄ±cÄ± bir URL'sine** sahip olmak
* **Yerel makinede Code Engine CLI dÄ±ÅŸÄ±nda** daÄŸÄ±tÄ±m yapmak

  istiyorsanÄ±z:

â¡ï¸ **Kubernetes** ve **konteyner teknolojileri** hakkÄ±nda daha fazla bilgi edinmeniz Ã¶nerilir.

---

### ğŸ Ãœcretsiz Kaynaklar

* **Ãœcretsiz Kubernetes kÃ¼mesi** edinebilirsiniz
* **Ãœcretsiz IBM Container Registry** hesabÄ± oluÅŸturabilirsiniz

Bu sayede uygulamanÄ±zÄ± daha baÄŸÄ±msÄ±z, esnek ve Ã¶lÃ§eklenebilir biÃ§imde internete taÅŸÄ±yabilirsiniz.

---
